{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "amazon_review.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAmLxUrZJ1zH",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvyFGHpIJ1zL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3ba779f9-3824-43f1-a6d3-eef8a2ab651f"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import roc_curve,auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QQoCvSqJ1zW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "dc52cfdf-41d6-4f58-8d82-e10e578c5bb7"
      },
      "source": [
        "# connection to the database\n",
        "con = sqlite3.connect('amazon_data/database.sqlite')\n",
        "\n",
        "# filtering psitive and negative reviews\n",
        "filtered_data = pd.read_sql_query(\"\"\"\n",
        "SELECT * FROM Reviews WHERE Score != 3\n",
        "\"\"\",con)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperationalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-344b1899b1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# connection to the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon_data/database.sqlite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# filtering psitive and negative reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m filtered_data = pd.read_sql_query(\"\"\"\n",
            "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlJwFf9YJ1zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Ia2vtXJ1zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seperate positive and negative reviews \n",
        "def partition(x):\n",
        "    if x<3:\n",
        "        return 'negative'\n",
        "    return 'positive'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9aiLsS1J1z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuiHsGNJ1z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actualScore = filtered_data['Score']\n",
        "positiveNegative = actualScore.map(partition)\n",
        "filtered_data['Score'] = positiveNegative\n",
        "# filtered_data['Score']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP3tmE_yJ10H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4ar1JfcJ10Q",
        "colab_type": "text"
      },
      "source": [
        "# Data cleaning: deduplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCSaNljBJ10S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display = pd.read_sql_query(\"\"\"\n",
        "SELECT * FROM Reviews WHERE Score != 3 AND UserId =\"AR5J8UI46CURR\"\n",
        "ORDER BY ProductID\n",
        "\"\"\",con)\n",
        "display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irKJ-Z3DJ10b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first sorting data according to productid in ascdending order\n",
        "sorted_data = filtered_data.sort_values('ProductId',axis=0,ascending=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbj3ar6QJ10i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove duplicate entries \n",
        "final = sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep='first',inplace=False)\n",
        "final.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXdu8mciJ10s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking what % of data still remains \n",
        "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5hsgIzjJ101",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some data have helpfulnessdenominator less than helpfulnessnumerator\n",
        "display = pd.read_sql_query(\"\"\"\n",
        "SELECT * FROM Reviews WHERE Score != 3 AND Id=44737 OR Id=64422\n",
        "ORDER BY ProductID\n",
        "\"\"\",con)\n",
        "display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLfy8gZMJ10-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = final[final.HelpfulnessNumerator <= final.HelpfulnessDenominator]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJBB8AH7J11E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH0vfn75J11O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final['Score'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpkIT56YJ11T",
        "colab_type": "text"
      },
      "source": [
        "# Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g63n3FgfJ11V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer()\n",
        "final_counts = count_vect.fit_transform(final['Text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW8UE6ofJ11f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(final_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QklFYLb1J11p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_counts.get_shape()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKWUJ67DJ11w",
        "colab_type": "text"
      },
      "source": [
        "# Text preprocessing (Stemming, stopword removal and lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlJ-nRk0J11x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find sentences containing HTML pages\n",
        "import re\n",
        "i =0 \n",
        "for sent in final['Text'].values:\n",
        "    if(len(re.findall('<.*?>',sent))):\n",
        "        print(i)\n",
        "        print(sent)\n",
        "        break;\n",
        "    i+=1;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuf-q0r7J113",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHe3f5qFJ11-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = set(stopwords.words('english'))#set of stopwords\n",
        "stop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teCiUUQtJ12E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing a snowball stemmer\n",
        "sno = nltk.stem.SnowballStemmer('english')\n",
        "sno"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcbLmx2rJ12L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to clean the word of any html tags\n",
        "def cleanhtml(sentence):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr,' ',sentence)\n",
        "    return cleantext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FupujaqHJ12S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean word of any puctuations\n",
        "def cleanpunc(sentence):\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)    \n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r'',cleaned)\n",
        "    return cleaned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLNi9uBOJ12b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sno.stem('tasty'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byZaIyueJ12h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for implementing step by step checks\n",
        "i=0\n",
        "str1=' '\n",
        "final_string=[]\n",
        "all_positive_words=[]\n",
        "all_negative_words=[]\n",
        "s=''\n",
        "for sent in final['Text'].values:\n",
        "    filtered_sentence=[]\n",
        "    for w in cleanhtml(sent).split():\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            print(cleaned_words)\n",
        "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):\n",
        "                s = (sno.stem(cleaned_words.lower())).encode('utf8')\n",
        "                filtered_sentence.append(s)\n",
        "                if(final['Score'].values)[i] == 'positive':\n",
        "                    all_positive_words.append(s)\n",
        "                if(final['Score'].values)[i] == 'negative':\n",
        "                    all_negative_words.append(s)\n",
        "            else:\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "    str1= b\" \".join(filtered_sentence)\n",
        "    final_string.append(str1)\n",
        "    i+=1\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX7b-S0RJ12n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final['CleanedText'] = final_string #adding column of cleaned text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boa2aN6nJ12x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA1bH0f7J122",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store the table into a sqlite database table for future\n",
        "conn = sqlite3.connect('final.sqlite')\n",
        "c= conn.cursor()\n",
        "conn.text_factory = str\n",
        "final.to_sql('Reviews',conn,flavor-None,schema=None,if_exists='replace')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT6n_tM_J12_",
        "colab_type": "text"
      },
      "source": [
        "# bigrams ngrams "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttH4vaUJJ13B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_dist_positive=nltk.FreqDist(all_positive_words)\n",
        "freq_dist_negative=nltk.FreqDist(all_negative_words)\n",
        "print(\"Most common frequent words:\",freq_dist_positive.most_common(20))\n",
        "print(\"Most common negative words:\",freq_dist_negative.most_common(20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH9LM_fFJ13J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing stop words like not should be avoided before building ngrams\n",
        "count_vect = CountVectorizer(ngram_range(1,2))\n",
        "final_bigram_counts = count_vect.fit_transform(final['Text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oumzMFvhJ13Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_bigram_counts.get_shape() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siIHwqY4J13W",
        "colab_type": "text"
      },
      "source": [
        "# tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojd_4lvgJ13X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf_vect = TfidfVectorizer(n_gram_range=(1,2))\n",
        "final_tf_idf = tf_idf_vect.fit_transform(final['Text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq5lait9J13f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_tf_idf.shape()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_ktZXIJ13n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = tf_idf_vect.get_feature_names()\n",
        "len(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOMm11mDJ13u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features[100000:100010]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73JOn3zwJ133",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final_tf_idf[3,:].toarray()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRqYAzzZJ13_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_tf_idf_feats(row,features,top_n=25):\n",
        "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
        "    top_feats = [(features[i],row[i]) for i in topn_ids]\n",
        "    df = pd.DataFrame(top_feats)\n",
        "    df.columns = ['feature','tfidf']\n",
        "    return df\n",
        "\n",
        "top_tfidf = top_tf_idf_feats(final_tf_idf[1,:].toarray()[0],features,25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HmrJFdzJ14T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_tfidf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNatMkLPJ14h",
        "colab_type": "text"
      },
      "source": [
        "# word2vec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snq6ZuLBJ14j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using google word2vec\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "\n",
        "# model = KeyedVectors.load_word2vec_format('....')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW193R4EJ14y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.wv['computer']\n",
        "# model.wv.similarity('woman','man')\n",
        "# model.wv.most_similar('woman')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foyQchR1J148",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train your own word2vec model\n",
        "import gensim\n",
        "i=0\n",
        "list_of_sent=[]\n",
        "\n",
        "for sent in final['Text'].values:\n",
        "    filtered_sentence=[]\n",
        "    sent = cleanhtml(sent)\n",
        "    for w in sent.split():\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            if(cleaned_words.isalpha()):\n",
        "                filtered_sentence.append(cleaned_words.lower())\n",
        "            else:\n",
        "                continue\n",
        "    list_of_sent.append(filtered_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmWEcKdlJ15G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final['Text'].values[0])\n",
        "print(\"***************************************************************\")\n",
        "print(list_of_sent[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL-W0Ie2J15Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = gensim.models.Word2Vec(list_of_sent,min_count=5,size=50,workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95wDfbQLJ15b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(w2v_model.wv.vocab)\n",
        "print(len(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA1PWlW3J15k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model.wv.most_similar('tasty')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKcULbd-J15q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect_feat = count_vect.get_feature_names()\n",
        "count_vect_feat.index('like')\n",
        "print(count_vect_feat[64055])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Vm57PwJ15w",
        "colab_type": "text"
      },
      "source": [
        "# avg w2v, tfidf-w2v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBQddcHtJ15x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avg word2vec\n",
        "sent_vectors = []\n",
        "for sent in list_of_sent:\n",
        "    sent_vec=np.zeros(50)\n",
        "    cnt_words=0\n",
        "    for word in sent:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words+=1\n",
        "        except:\n",
        "            pass\n",
        "    sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)\n",
        "    \n",
        "print(len(sent_vectors))\n",
        "print(len(sent_vectors[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxR1WgcoJ156",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf-idf weighted word2vec\n",
        "tfidf_feat = tf_idf_vect.get_features_names()\n",
        "\n",
        "tfidf_sent_vectors = []\n",
        "row=0\n",
        "for sent in list_of_sent:\n",
        "    sent_vec=np.zeros(50)\n",
        "    weighted_sum=0\n",
        "    for word in sent:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            tfidf = final_tf_idf[row,tfidf_feat.index(word)]\n",
        "            sent_vec += (vec*tf_idf)\n",
        "            weighted_sum += tf_idf\n",
        "        except:\n",
        "            pass\n",
        "    sent_vec /= weighted_sum\n",
        "    tfidf_sent_vectors.append(sent_vec)\n",
        "    row += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNmEPxjWJ15-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKU1wBPOJ16N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_g0kHM6J16V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}